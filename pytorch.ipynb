{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjH5smhmef6MTGnzCAllkV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoolCodeMan/intro2LT/blob/lauri/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5aIokor8rWI"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4ESgswqNAtz"
      },
      "source": [
        "# **Links**\n",
        "\n",
        "* https://github.com/CoolCodeMan/intro2LT/blob/lauri/tfidf-bow-ja-linearSVC.ipynb\n",
        "* https://github.com/graykode/nlp-tutorial\n",
        "* https://colab.research.google.com/github/graykode/nlp-tutorial/blob/master/1-1.NNLM/NNLM.ipynb\n",
        "* https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#sphx-glr-beginner-nlp-word-embeddings-tutorial-py\n",
        "* https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "* https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding\n",
        "* https://stackoverflow.com/questions/50747947/embedding-in-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aU7tKv6D7n0"
      },
      "source": [
        "!wget -q -O anger-train.tsv http://dl.turkunlp.org/TKO_8966_2021-projects/anger-annotation/train.tsv\n",
        "!wget -q -O anger-test.tsv http://dl.turkunlp.org/TKO_8966_2021-projects/anger-annotation/test.tsv\n",
        "!wget -q -O anger-dev.tsv http://dl.turkunlp.org/TKO_8966_2021-projects/anger-annotation/dev.tsv\n",
        "\n",
        "!wget -q -O joy-train.tsv http://dl.turkunlp.org/TKO_8966_2021-projects/joy-annotation/train.tsv\n",
        "!wget -q -O joy-test.tsv http://dl.turkunlp.org/TKO_8966_2021-projects/joy-annotation/test.tsv\n",
        "!wget -q -O joy-dev.tsv http://dl.turkunlp.org/TKO_8966_2021-projects/joy-annotation/dev.tsv"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfEJgpWHEl4e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as functional\n",
        "import torch.optim as optim"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIkl71kcE13l"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, embed_size, vector_size, context_size):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.EmbeddingBag(embed_size, vector_size, sparse=True)\n",
        "    # self.layer2 = nn.Linear(vector_size * context_size, 128)\n",
        "    # self.layer2 = nn.Linear(vector_size, 128)\n",
        "    self.layer2 = nn.Linear(vector_size, context_size)\n",
        "    # self.layer4 = nn.Linear(3, 3)\n",
        "\n",
        "  def forward(self, X, offset):\n",
        "    out = self.layer1(X, offset)\n",
        "    out = self.layer2(out)\n",
        "    # out = torch.sigmoid(out)\n",
        "    return out"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSGf6jQeIH8j"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKAgpNSBJTi0"
      },
      "source": [
        "joy = pd.read_csv('/content/joy-train.tsv', error_bad_lines=False, header=0, names=['emotion','text'], sep='\\t')\n",
        "anger = pd.read_csv('/content/anger-train.tsv', error_bad_lines=False, header=0, names=['emotion','text'], sep='\\t')"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e-MlENsJtse"
      },
      "source": [
        "dataframe = pd.concat([joy, anger])\n",
        "dataframe['emotion'].replace({'not-joy':'neutral', 'not-anger':'neutral'}, inplace=True)\n",
        "# dataframe['emotion'].replace({'not-joy':0, 'not-anger':0, 'joy':1, 'anger':2}, inplace=True)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZJxQOWjKFcl"
      },
      "source": [
        "import sklearn.utils\n",
        "\n",
        "def shuffle(data):\n",
        "  data = sklearn.utils.shuffle(data)\n",
        "  data.reset_index(inplace=True, drop=True)\n",
        "  return data"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PLs3XAnLKZRQ",
        "outputId": "108edcb6-e91c-4a66-e8e4-9a3b88826e10"
      },
      "source": [
        "dataframe = shuffle(dataframe)\n",
        "dataframe.tail()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020</th>\n",
              "      <td>neutral</td>\n",
              "      <td>En koskaan tiedä etukäteen, milloin olen nero.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021</th>\n",
              "      <td>joy</td>\n",
              "      <td>Täällä on hevonenkin valmiina.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Se kertoisi sen, mitä tiedämme, kertomalla sen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Niinpä. Valamiehistö muistaa kuvat, joissa Car...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Usko Jumalaan on ihmisen normaali ja terve elä...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      emotion                                               text\n",
              "2020  neutral     En koskaan tiedä etukäteen, milloin olen nero.\n",
              "2021      joy                     Täällä on hevonenkin valmiina.\n",
              "2022  neutral  Se kertoisi sen, mitä tiedämme, kertomalla sen...\n",
              "2023  neutral  Niinpä. Valamiehistö muistaa kuvat, joissa Car...\n",
              "2024  neutral  Usko Jumalaan on ihmisen normaali ja terve elä..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AREtOuhOKzEO",
        "outputId": "802b0aa4-3d12-4534-a4b6-fefac7ded1d1"
      },
      "source": [
        "words = []\n",
        "for x in dataframe['text']:\n",
        "  l = x.split(' ')\n",
        "  for y in l:\n",
        "    words.append(y)\n",
        "\n",
        "len(words)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19345"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU3-speoLhBj"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu9Uloq7Njlz",
        "outputId": "ca805105-0b53-4346-c45a-9968a5b26de3"
      },
      "source": [
        "vocab = Counter(words)\n",
        "vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9597"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5MwxoKQOSng",
        "outputId": "bf493e25-0cea-4cb3-c1ad-bbc72212e9ce"
      },
      "source": [
        "word2vec = {word: ind for ind, word in enumerate(vocab)}\n",
        "list(word2vec)[:20]"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['on',\n",
              " ',',\n",
              " 'ja',\n",
              " '.',\n",
              " 'että',\n",
              " 'ei',\n",
              " 'se',\n",
              " 'oli',\n",
              " 'ole',\n",
              " 'mutta',\n",
              " 'kun',\n",
              " 'niin',\n",
              " 'kuin',\n",
              " 'En',\n",
              " '-',\n",
              " 'sen',\n",
              " 'jos',\n",
              " 'olla',\n",
              " 'ovat',\n",
              " 'joka']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR4yt3wyOmqX",
        "outputId": "3f5fa347-7074-484c-ea2f-b71cbfda5763"
      },
      "source": [
        "encoded_sentences_example = [word2vec[word] for word in words]\n",
        "print(list(encoded_sentences_example)[:20])"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[29, 416, 1980, 193, 1981, 854, 855, 13, 32, 1982, 272, 36, 553, 1983, 1984, 1985, 122, 37, 856, 1986]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6423AxFRvyx"
      },
      "source": [
        "# [joy, anger, neutral]\n",
        "\n",
        "labels = dataframe['emotion']\n",
        "y = []\n",
        "for i in labels:\n",
        "  if i == 'joy':\n",
        "    y.append([1,0,0])\n",
        "  elif i == 'anger':\n",
        "    y.append([0,1,0])\n",
        "  elif i == 'neutral':\n",
        "    y.append([0,0,1])\n",
        "y = torch.tensor(y).float()"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60fZcI2hO6NA"
      },
      "source": [
        "vec_size = 200\n",
        "context_s = 3\n",
        "model = Net(vocab_size, vec_size, context_s)\n",
        "\n",
        "loss_function = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.005)"
      ],
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i81hENo5P79s",
        "outputId": "e008325e-c9d0-4ffb-adba-bc8f21de3c9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentences = dataframe['text']\n",
        "for i in range(10):\n",
        "  running_loss = 0.0\n",
        "  for epoch in range(2024):\n",
        "    encoded_sentence = torch.tensor([word2vec[word] for word in sentences[epoch].split(' ')])\n",
        "    model.zero_grad()\n",
        "\n",
        "    out = model(encoded_sentence, torch.tensor([0]))\n",
        "    loss = loss_function(out, y[epoch])\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if epoch % 100 == 0:\n",
        "      # print(epoch, loss.item())\n",
        "      print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
        "      # running_loss = 0.0"
      ],
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,     1] loss: 0.000\n",
            "[101,     1] loss: 0.006\n",
            "[201,     1] loss: 0.013\n",
            "[301,     1] loss: 0.019\n",
            "[401,     1] loss: 0.026\n",
            "[501,     1] loss: 0.033\n",
            "[601,     1] loss: 0.042\n",
            "[701,     1] loss: 0.050\n",
            "[801,     1] loss: 0.058\n",
            "[901,     1] loss: 0.065\n",
            "[1001,     1] loss: 0.072\n",
            "[1101,     1] loss: 0.080\n",
            "[1201,     1] loss: 0.087\n",
            "[1301,     1] loss: 0.094\n",
            "[1401,     1] loss: 0.101\n",
            "[1501,     1] loss: 0.107\n",
            "[1601,     1] loss: 0.114\n",
            "[1701,     1] loss: 0.121\n",
            "[1801,     1] loss: 0.128\n",
            "[1901,     1] loss: 0.136\n",
            "[2001,     1] loss: 0.142\n",
            "[1,     2] loss: 0.000\n",
            "[101,     2] loss: 0.006\n",
            "[201,     2] loss: 0.013\n",
            "[301,     2] loss: 0.019\n",
            "[401,     2] loss: 0.026\n",
            "[501,     2] loss: 0.033\n",
            "[601,     2] loss: 0.042\n",
            "[701,     2] loss: 0.050\n",
            "[801,     2] loss: 0.058\n",
            "[901,     2] loss: 0.065\n",
            "[1001,     2] loss: 0.072\n",
            "[1101,     2] loss: 0.080\n",
            "[1201,     2] loss: 0.087\n",
            "[1301,     2] loss: 0.094\n",
            "[1401,     2] loss: 0.101\n",
            "[1501,     2] loss: 0.107\n",
            "[1601,     2] loss: 0.114\n",
            "[1701,     2] loss: 0.120\n",
            "[1801,     2] loss: 0.128\n",
            "[1901,     2] loss: 0.136\n",
            "[2001,     2] loss: 0.142\n",
            "[1,     3] loss: 0.000\n",
            "[101,     3] loss: 0.006\n",
            "[201,     3] loss: 0.013\n",
            "[301,     3] loss: 0.019\n",
            "[401,     3] loss: 0.026\n",
            "[501,     3] loss: 0.033\n",
            "[601,     3] loss: 0.042\n",
            "[701,     3] loss: 0.049\n",
            "[801,     3] loss: 0.058\n",
            "[901,     3] loss: 0.065\n",
            "[1001,     3] loss: 0.072\n",
            "[1101,     3] loss: 0.080\n",
            "[1201,     3] loss: 0.087\n",
            "[1301,     3] loss: 0.094\n",
            "[1401,     3] loss: 0.101\n",
            "[1501,     3] loss: 0.107\n",
            "[1601,     3] loss: 0.114\n",
            "[1701,     3] loss: 0.120\n",
            "[1801,     3] loss: 0.128\n",
            "[1901,     3] loss: 0.136\n",
            "[2001,     3] loss: 0.142\n",
            "[1,     4] loss: 0.000\n",
            "[101,     4] loss: 0.006\n",
            "[201,     4] loss: 0.013\n",
            "[301,     4] loss: 0.019\n",
            "[401,     4] loss: 0.026\n",
            "[501,     4] loss: 0.033\n",
            "[601,     4] loss: 0.042\n",
            "[701,     4] loss: 0.049\n",
            "[801,     4] loss: 0.057\n",
            "[901,     4] loss: 0.065\n",
            "[1001,     4] loss: 0.072\n",
            "[1101,     4] loss: 0.080\n",
            "[1201,     4] loss: 0.087\n",
            "[1301,     4] loss: 0.094\n",
            "[1401,     4] loss: 0.101\n",
            "[1501,     4] loss: 0.107\n",
            "[1601,     4] loss: 0.114\n",
            "[1701,     4] loss: 0.120\n",
            "[1801,     4] loss: 0.128\n",
            "[1901,     4] loss: 0.136\n",
            "[2001,     4] loss: 0.142\n",
            "[1,     5] loss: 0.000\n",
            "[101,     5] loss: 0.006\n",
            "[201,     5] loss: 0.013\n",
            "[301,     5] loss: 0.019\n",
            "[401,     5] loss: 0.026\n",
            "[501,     5] loss: 0.033\n",
            "[601,     5] loss: 0.042\n",
            "[701,     5] loss: 0.049\n",
            "[801,     5] loss: 0.057\n",
            "[901,     5] loss: 0.064\n",
            "[1001,     5] loss: 0.072\n",
            "[1101,     5] loss: 0.079\n",
            "[1201,     5] loss: 0.087\n",
            "[1301,     5] loss: 0.094\n",
            "[1401,     5] loss: 0.101\n",
            "[1501,     5] loss: 0.107\n",
            "[1601,     5] loss: 0.114\n",
            "[1701,     5] loss: 0.120\n",
            "[1801,     5] loss: 0.128\n",
            "[1901,     5] loss: 0.136\n",
            "[2001,     5] loss: 0.142\n",
            "[1,     6] loss: 0.000\n",
            "[101,     6] loss: 0.006\n",
            "[201,     6] loss: 0.013\n",
            "[301,     6] loss: 0.019\n",
            "[401,     6] loss: 0.026\n",
            "[501,     6] loss: 0.033\n",
            "[601,     6] loss: 0.042\n",
            "[701,     6] loss: 0.049\n",
            "[801,     6] loss: 0.057\n",
            "[901,     6] loss: 0.064\n",
            "[1001,     6] loss: 0.072\n",
            "[1101,     6] loss: 0.079\n",
            "[1201,     6] loss: 0.087\n",
            "[1301,     6] loss: 0.094\n",
            "[1401,     6] loss: 0.101\n",
            "[1501,     6] loss: 0.107\n",
            "[1601,     6] loss: 0.114\n",
            "[1701,     6] loss: 0.120\n",
            "[1801,     6] loss: 0.128\n",
            "[1901,     6] loss: 0.136\n",
            "[2001,     6] loss: 0.142\n",
            "[1,     7] loss: 0.000\n",
            "[101,     7] loss: 0.006\n",
            "[201,     7] loss: 0.013\n",
            "[301,     7] loss: 0.019\n",
            "[401,     7] loss: 0.026\n",
            "[501,     7] loss: 0.033\n",
            "[601,     7] loss: 0.042\n",
            "[701,     7] loss: 0.049\n",
            "[801,     7] loss: 0.057\n",
            "[901,     7] loss: 0.064\n",
            "[1001,     7] loss: 0.072\n",
            "[1101,     7] loss: 0.079\n",
            "[1201,     7] loss: 0.087\n",
            "[1301,     7] loss: 0.094\n",
            "[1401,     7] loss: 0.100\n",
            "[1501,     7] loss: 0.107\n",
            "[1601,     7] loss: 0.114\n",
            "[1701,     7] loss: 0.120\n",
            "[1801,     7] loss: 0.128\n",
            "[1901,     7] loss: 0.136\n",
            "[2001,     7] loss: 0.142\n",
            "[1,     8] loss: 0.000\n",
            "[101,     8] loss: 0.006\n",
            "[201,     8] loss: 0.013\n",
            "[301,     8] loss: 0.019\n",
            "[401,     8] loss: 0.026\n",
            "[501,     8] loss: 0.033\n",
            "[601,     8] loss: 0.042\n",
            "[701,     8] loss: 0.049\n",
            "[801,     8] loss: 0.057\n",
            "[901,     8] loss: 0.064\n",
            "[1001,     8] loss: 0.072\n",
            "[1101,     8] loss: 0.079\n",
            "[1201,     8] loss: 0.087\n",
            "[1301,     8] loss: 0.094\n",
            "[1401,     8] loss: 0.100\n",
            "[1501,     8] loss: 0.107\n",
            "[1601,     8] loss: 0.114\n",
            "[1701,     8] loss: 0.120\n",
            "[1801,     8] loss: 0.128\n",
            "[1901,     8] loss: 0.136\n",
            "[2001,     8] loss: 0.142\n",
            "[1,     9] loss: 0.000\n",
            "[101,     9] loss: 0.006\n",
            "[201,     9] loss: 0.013\n",
            "[301,     9] loss: 0.019\n",
            "[401,     9] loss: 0.026\n",
            "[501,     9] loss: 0.033\n",
            "[601,     9] loss: 0.041\n",
            "[701,     9] loss: 0.049\n",
            "[801,     9] loss: 0.057\n",
            "[901,     9] loss: 0.064\n",
            "[1001,     9] loss: 0.072\n",
            "[1101,     9] loss: 0.079\n",
            "[1201,     9] loss: 0.087\n",
            "[1301,     9] loss: 0.094\n",
            "[1401,     9] loss: 0.100\n",
            "[1501,     9] loss: 0.107\n",
            "[1601,     9] loss: 0.114\n",
            "[1701,     9] loss: 0.120\n",
            "[1801,     9] loss: 0.128\n",
            "[1901,     9] loss: 0.135\n",
            "[2001,     9] loss: 0.141\n",
            "[1,    10] loss: 0.000\n",
            "[101,    10] loss: 0.006\n",
            "[201,    10] loss: 0.013\n",
            "[301,    10] loss: 0.019\n",
            "[401,    10] loss: 0.026\n",
            "[501,    10] loss: 0.033\n",
            "[601,    10] loss: 0.041\n",
            "[701,    10] loss: 0.049\n",
            "[801,    10] loss: 0.057\n",
            "[901,    10] loss: 0.064\n",
            "[1001,    10] loss: 0.072\n",
            "[1101,    10] loss: 0.079\n",
            "[1201,    10] loss: 0.087\n",
            "[1301,    10] loss: 0.094\n",
            "[1401,    10] loss: 0.100\n",
            "[1501,    10] loss: 0.107\n",
            "[1601,    10] loss: 0.114\n",
            "[1701,    10] loss: 0.120\n",
            "[1801,    10] loss: 0.128\n",
            "[1901,    10] loss: 0.135\n",
            "[2001,    10] loss: 0.141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AhC1h7ppXTB"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcuRNS_LSh7n",
        "outputId": "303a1ff3-c16b-4c25-cb66-16d5ddfaf293",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "size = 2024\n",
        "total = 0\n",
        "for i in range(size):\n",
        "  encoded_sentence = torch.tensor([word2vec[word] for word in sentences[i].split(' ')])\n",
        "  pred = model(encoded_sentence, torch.tensor([0]))\n",
        "  n1 = pred.detach().numpy().argmax()\n",
        "  n2 = y[i].detach().numpy().argmax()\n",
        "  if n2 == n1:\n",
        "    total += 1\n",
        "\n",
        "print(\"TRAIN {:.2f}\".format(total/size*100), '%')"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN 73.47 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toGGq-Vo6Z26"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}