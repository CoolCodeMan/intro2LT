{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcDorrfFC6ZpXMn4DyFg/q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoolCodeMan/intro2LT/blob/lauri/pytorch-embed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5aIokor8rWI"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4ESgswqNAtz"
      },
      "source": [
        "# **Links**\n",
        "\n",
        "* https://github.com/CoolCodeMan/intro2LT/blob/lauri/tfidf-bow-ja-linearSVC.ipynb\n",
        "* https://github.com/graykode/nlp-tutorial\n",
        "* https://colab.research.google.com/github/graykode/nlp-tutorial/blob/master/1-1.NNLM/NNLM.ipynb\n",
        "* https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#sphx-glr-beginner-nlp-word-embeddings-tutorial-py\n",
        "* https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "* https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding\n",
        "* https://stackoverflow.com/questions/50747947/embedding-in-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aU7tKv6D7n0"
      },
      "source": [
        "!wget -q -O anger-train.tsv http://dl.turkunlp.org/TKO_8966_2021-projects/anger-annotation/train.tsv\n",
        "!wget -q -O anger-test.tsv http://dl.turkunlp.org/TKO_8966_2021-projects/anger-annotation/test.tsv\n",
        "!wget -q -O anger-dev.tsv http://dl.turkunlp.org/TKO_8966_2021-projects/anger-annotation/dev.tsv\n",
        "\n",
        "!wget -q -O joy-train.tsv http://dl.turkunlp.org/TKO_8966_2021-projects/joy-annotation/train.tsv\n",
        "!wget -q -O joy-test.tsv http://dl.turkunlp.org/TKO_8966_2021-projects/joy-annotation/test.tsv\n",
        "!wget -q -O joy-dev.tsv http://dl.turkunlp.org/TKO_8966_2021-projects/joy-annotation/dev.tsv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSGf6jQeIH8j"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKAgpNSBJTi0"
      },
      "source": [
        "joy = pd.read_csv('/content/joy-train.tsv', error_bad_lines=False, header=0, names=['emotion','text'], sep='\\t')\n",
        "anger = pd.read_csv('/content/anger-train.tsv', error_bad_lines=False, header=0, names=['emotion','text'], sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e-MlENsJtse"
      },
      "source": [
        "dataframe = pd.concat([joy, anger])\n",
        "dataframe['emotion'].replace({'not-joy':'neutral', 'not-anger':'neutral'}, inplace=True)\n",
        "# dataframe['emotion'].replace({'not-joy':0, 'not-anger':0, 'joy':1, 'anger':2}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZJxQOWjKFcl"
      },
      "source": [
        "import sklearn.utils\n",
        "\n",
        "def shuffle(data):\n",
        "  data = sklearn.utils.shuffle(data)\n",
        "  data.reset_index(inplace=True, drop=True)\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PLs3XAnLKZRQ",
        "outputId": "108edcb6-e91c-4a66-e8e4-9a3b88826e10"
      },
      "source": [
        "dataframe = shuffle(dataframe)\n",
        "dataframe.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020</th>\n",
              "      <td>neutral</td>\n",
              "      <td>En koskaan tiedä etukäteen, milloin olen nero.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021</th>\n",
              "      <td>joy</td>\n",
              "      <td>Täällä on hevonenkin valmiina.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Se kertoisi sen, mitä tiedämme, kertomalla sen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Niinpä. Valamiehistö muistaa kuvat, joissa Car...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Usko Jumalaan on ihmisen normaali ja terve elä...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      emotion                                               text\n",
              "2020  neutral     En koskaan tiedä etukäteen, milloin olen nero.\n",
              "2021      joy                     Täällä on hevonenkin valmiina.\n",
              "2022  neutral  Se kertoisi sen, mitä tiedämme, kertomalla sen...\n",
              "2023  neutral  Niinpä. Valamiehistö muistaa kuvat, joissa Car...\n",
              "2024  neutral  Usko Jumalaan on ihmisen normaali ja terve elä..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AREtOuhOKzEO",
        "outputId": "802b0aa4-3d12-4534-a4b6-fefac7ded1d1"
      },
      "source": [
        "words = []\n",
        "for x in dataframe['text']:\n",
        "  l = x.split(' ')\n",
        "  for y in l:\n",
        "    words.append(y)\n",
        "\n",
        "len(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19345"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU3-speoLhBj"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu9Uloq7Njlz",
        "outputId": "ca805105-0b53-4346-c45a-9968a5b26de3"
      },
      "source": [
        "vocab = Counter(words)\n",
        "vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9597"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5MwxoKQOSng",
        "outputId": "40ae38b2-5f6a-4f63-bb24-0fe51a0d6fe1"
      },
      "source": [
        "# word2vec = {word: ind for ind, word in enumerate(vocab)}\n",
        "word2vec = {word: ind + 1 for ind, word in enumerate(vocab)}\n",
        "list(word2vec)[:20]"
      ],
      "execution_count": 482,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['on',\n",
              " ',',\n",
              " 'ja',\n",
              " '.',\n",
              " 'että',\n",
              " 'ei',\n",
              " 'se',\n",
              " 'oli',\n",
              " 'ole',\n",
              " 'mutta',\n",
              " 'kun',\n",
              " 'niin',\n",
              " 'kuin',\n",
              " 'En',\n",
              " '-',\n",
              " 'sen',\n",
              " 'jos',\n",
              " 'olla',\n",
              " 'ovat',\n",
              " 'joka']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 482
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR4yt3wyOmqX",
        "outputId": "db021d14-b98c-40c4-9482-1bdc263fba6e"
      },
      "source": [
        "encoded_sentences_example = [word2vec[word] for word in words]\n",
        "print(list(encoded_sentences_example)[:20])"
      ],
      "execution_count": 483,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[30, 417, 1981, 194, 1982, 855, 856, 14, 33, 1983, 273, 37, 554, 1984, 1985, 1986, 123, 38, 857, 1987]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6423AxFRvyx"
      },
      "source": [
        "# [joy, anger, neutral]\n",
        "\n",
        "labels = dataframe['emotion']\n",
        "y = []\n",
        "for i in labels:\n",
        "  if i == 'joy':\n",
        "    y.append([1,0,0])\n",
        "  elif i == 'anger':\n",
        "    y.append([0,1,0])\n",
        "  elif i == 'neutral':\n",
        "    y.append([0,0,1])\n",
        "y = torch.tensor(y).float()"
      ],
      "execution_count": 484,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AhC1h7ppXTB"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 689,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfEJgpWHEl4e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as functional\n",
        "import torch.optim as optim"
      ],
      "execution_count": 690,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcuRNS_LSh7n"
      },
      "source": [
        "def score(model, dataset, labels, dataset_size=2024):\n",
        "  total = 0\n",
        "  for i in range(dataset_size):\n",
        "    encoded_sentence = torch.tensor([word2vec[word] for word in dataset[i].split(' ')])\n",
        "    pred = model(encoded_sentence)\n",
        "    n1 = pred.detach().numpy().argmax()\n",
        "    n2 = y[i].detach().numpy().argmax()\n",
        "    if n2 == n1:\n",
        "      total += 1\n",
        "    \n",
        "  print(\"TRAIN {:.2f}\".format(total/dataset_size*100), '%')"
      ],
      "execution_count": 699,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIkl71kcE13l"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, embed_size, vector_size, context_size):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    # self.embed = nn.EmbeddingBag(embed_size, vector_size, sparse=True)\n",
        "    self.embed = nn.Embedding(embed_size, vector_size, padding_idx=0, sparse=True)\n",
        "\n",
        "    self.conv1 = nn.Conv1d(128, 50, kernel_size=1)\n",
        "    self.conv2 = nn.Conv1d(50, 1, kernel_size=1)\n",
        "    \n",
        "    self.fc1 = nn.Linear(vector_size, 50)\n",
        "    self.fc2 = nn.Linear(50, context_size)\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    p = int((128-X.shape[0])/2)\n",
        "    if X.shape[0] % 2 == 0:\n",
        "      out = functional.pad(X, pad=(p,p))\n",
        "    else:\n",
        "      out = functional.pad(X, pad=(p,p+1))\n",
        "\n",
        "    out = self.embed(out)\n",
        "\n",
        "    out = out.clone().detach()\n",
        "    out = out.float()\n",
        "    out.requires_grad = True\n",
        "\n",
        "    out = out.view(out.shape[1],out.shape[0],1)\n",
        "    out = self.conv1(out)\n",
        "\n",
        "    out = self.conv2(out)\n",
        "\n",
        "    out = out.view(out.shape[0],out.shape[1])\n",
        "    out = torch.transpose(out,0,1)\n",
        "    \n",
        "    out = self.fc1(out)\n",
        "\n",
        "    out = torch.sigmoid(out)\n",
        "    out = self.fc2(out)\n",
        "\n",
        "    out = out.view(out.shape[1])\n",
        "\n",
        "    return out"
      ],
      "execution_count": 772,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60fZcI2hO6NA"
      },
      "source": [
        "vec_size = 50\n",
        "context_s = 3\n",
        "model = Net(vocab_size, vec_size, context_s)\n",
        "\n",
        "loss_function = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9)"
      ],
      "execution_count": 779,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i81hENo5P79s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d237276-22b4-4e64-95e0-64d4d124c4f3"
      },
      "source": [
        "sentences = dataframe['text']\n",
        "for i in range(2):\n",
        "  running_loss = 0.0\n",
        "  for epoch in range(2024):\n",
        "    encoded_sentence = torch.tensor([word2vec[word] for word in sentences[epoch].split(' ')])\n",
        "    model.zero_grad()\n",
        "\n",
        "    # out = model(encoded_sentence, torch.tensor([0]))\n",
        "    out = model(encoded_sentence)\n",
        "    loss = loss_function(out, y[epoch])\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if epoch % 100 == 0:\n",
        "      print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2024))\n",
        "      # score(model, sentences[:50], y, dataset_size=50)\n",
        "      # running_loss = 0.0"
      ],
      "execution_count": 780,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,     1] loss: 0.000\n",
            "[101,     1] loss: 0.015\n",
            "[201,     1] loss: 0.024\n",
            "[301,     1] loss: 0.033\n",
            "[401,     1] loss: 0.042\n",
            "[501,     1] loss: 0.052\n",
            "[601,     1] loss: 0.062\n",
            "[701,     1] loss: 0.074\n",
            "[801,     1] loss: 0.084\n",
            "[901,     1] loss: 0.093\n",
            "[1001,     1] loss: 0.103\n",
            "[1101,     1] loss: 0.113\n",
            "[1201,     1] loss: 0.122\n",
            "[1301,     1] loss: 0.130\n",
            "[1401,     1] loss: 0.139\n",
            "[1501,     1] loss: 0.148\n",
            "[1601,     1] loss: 0.156\n",
            "[1701,     1] loss: 0.163\n",
            "[1801,     1] loss: 0.172\n",
            "[1901,     1] loss: 0.183\n",
            "[2001,     1] loss: 0.192\n",
            "[1,     2] loss: 0.000\n",
            "[101,     2] loss: 0.007\n",
            "[201,     2] loss: 0.017\n",
            "[301,     2] loss: 0.026\n",
            "[401,     2] loss: 0.034\n",
            "[501,     2] loss: 0.045\n",
            "[601,     2] loss: 0.055\n",
            "[701,     2] loss: 0.066\n",
            "[801,     2] loss: 0.077\n",
            "[901,     2] loss: 0.086\n",
            "[1001,     2] loss: 0.096\n",
            "[1101,     2] loss: 0.105\n",
            "[1201,     2] loss: 0.114\n",
            "[1301,     2] loss: 0.123\n",
            "[1401,     2] loss: 0.132\n",
            "[1501,     2] loss: 0.140\n",
            "[1601,     2] loss: 0.149\n",
            "[1701,     2] loss: 0.156\n",
            "[1801,     2] loss: 0.165\n",
            "[1901,     2] loss: 0.175\n",
            "[2001,     2] loss: 0.184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qreu-uWStnTi",
        "outputId": "0d207172-b68f-45b0-f934-9e039aebc25b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score(model, sentences, y)"
      ],
      "execution_count": 781,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN 68.97 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXAmp92U9vM1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}